# Udacity Deep Learning NanoDegree

This is my Deep Learning projects related to Udacity Deep Learning Nano Degree. It mains contains two parts:

- Practices: Tutorial notebooks which lead you through implementing models such as CNN, RNN, GAN.
- Projects: Projects which are reviewed by Udacity experts.

# Practices

* [Sentiment Analysis with Numpy](/sentiment-network): [Andrew Trask](http://iamtrask.github.io/) Building a sentiment analysis model, predicting if some text is positive or negative.
* [Intro to TensorFlow](/intro-to-tensorflow): Starting building neural networks with Tensorflow.
* [Weight Intialization](/weight-initialization): Explore how initializing network weights affects performance.
* [Autoencoders](/autoencoder): Build models for image compression and denoising, using feed-forward and convolution networks in TensorFlow.
* [Transfer Learning (ConvNet)](/transfer-learning). In practice, most people don't train their own large networkd on huge datasets, but use pretrained networks such as VGGnet. Here you'll use VGGnet to classify images of flowers without training a network on the images themselves.
* [Intro to Recurrent Networks (Character-wise RNN)](/intro-to-rnns): Recurrent neural networks are able to use information about the sequence of data, such as the sequence of characters in text.
* [Embeddings (Word2Vec)](/embeddings): Implement the Word2Vec model to find semantic representations of words for use in natural language processing.
* [Sentiment Analysis RNN](/sentiment-rnn): Implement a recurrent neural network that can predict if a text sample is positive or negative.
* [Tensorboard](/tensorboard): Use TensorBoard to visualize the network graph, as well as how parameters change through training.
* [Reinforcement Learning (Q-Learning)](/reinforcement): Implement a deep Q-learning network to play a simple game from OpenAI Gym.
* [Sequence to sequence](/seq2seq): Implement a sequence-to-sequence recurrent network.
* [Batch normalization](/batch-norm): Learn how to improve training rates and network stability with batch normalizations.
* [Generative Adversatial Network on MNIST](/gan_mnist): Train a simple generative adversarial network on the MNIST dataset.
* [Deep Convolutional GAN (DCGAN)](/dcgan-svhn): Implement a DCGAN to generate new images based on the Street View House Numbers (SVHN) dataset.
* [Intro to TFLearn](/intro-to-tflearn): A couple introductions to a high-level library for building neural networks.

# Projects

* [Your First Neural Network](/first-neural-network): Implement a neural network in Numpy to predict bike rentals.
* [Image classification](/image-classification): Build a convolutional neural network with TensorFlow to classify CIFAR-10 images.
* [Text Generation](/tv-script-generation): Train a recurrent neural network on scripts from The Simpson's (copyright Fox) to generate new scripts.
* [Machine Translation](/language-translation): Train a sequence to sequence network for English to French translation (on a simple dataset)
* [Face Generation](/face_generation): Use a DCGAN on the CelebA dataset to generate images of novel and realistic human faces.

# Certification

![Certification](http://7xlwwh.com1.z0.glb.clouddn.com/udacity_certification.png)

# Thanks

A big thank to all the members from the Udacity Deep Learning course. It really help me a lot to understand and grasp deep learning knowledge.
